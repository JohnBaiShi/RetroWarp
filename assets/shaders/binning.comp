#version 450
#extension GL_EXT_shader_16bit_storage : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_EXT_scalar_block_layout : require

#if SUBGROUP
#extension GL_KHR_shader_subgroup_basic : require
#extension GL_KHR_shader_subgroup_ballot : require
#extension GL_KHR_shader_subgroup_arithmetic : require
layout(local_size_x_id = 0) in;
#else
layout(local_size_x = 512) in;
#endif

layout(constant_id = 1) const uint PER_WAVE_TILES_X = 8u;
layout(constant_id = 2) const uint PER_WAVE_TILES_Y = 4u;
layout(constant_id = 3) const uint NUM_SLICES = 16u;
const uint BITS_PER_SLICE = 32u / NUM_SLICES;

layout(std430, set = 0, binding = 0) writeonly buffer TileBitmask
{
    uint binned_bitmask[];
};

#define RENDER_STATE_INDEX_BUFFER 4
#define RENDER_STATE_BUFFER 5
#include "render_state.h"

#define PRIMITIVE_SETUP_POS_BUFFER 1
#include "rasterizer_helpers.h"

layout(std430, set = 0, binding = 2) readonly buffer TileBitmaskLowRes
{
    uint binned_bitmask_low_res[];
};

layout(std430, set = 0, binding = 3) writeonly buffer TileBitmaskCoarse
{
    uint binned_bitmask_coarse[];
};

#if !UBERSHADER
layout(std430, set = 0, binding = 6) writeonly buffer TileInstanceOffset
{
    uint16_t tile_instance_offset[];
};

layout(std430, set = 0, binding = 7) buffer IndirectBuffer
{
    uvec4 item_counts_per_variant[];
};

struct TileRasterWork
{
    uint16_t tile_x, tile_y;
    uint16_t tile_instance;
    uint16_t primitive;
};

layout(std430, set = 0, binding = 8) writeonly buffer WorkList
{
    u16vec4 tile_raster_work[];
};

layout(std430, set = 0, binding = 9) uniform StateIndex
{
    uint8_t state_indices[MAX_PRIMITIVES];
};
#endif

shared uint shared_group_binning[NUM_SLICES][PER_WAVE_TILES_Y][PER_WAVE_TILES_X];

void main()
{
#if SUBGROUP
    uint local_index = gl_SubgroupInvocationID + gl_SubgroupID * gl_SubgroupSize;
#else
    uint local_index = gl_LocalInvocationIndex;
#endif

    uint local_tile_x = local_index & (PER_WAVE_TILES_X - 1u);
    uint local_tile_y = (local_index / PER_WAVE_TILES_X) & (PER_WAVE_TILES_Y - 1u);
    ivec2 tile = ivec2(gl_WorkGroupID.yz) * ivec2(PER_WAVE_TILES_X, PER_WAVE_TILES_Y) + ivec2(local_tile_x, local_tile_y);
    int linear_tile = tile.y * MAX_TILES_X + tile.x;

    ivec2 base_coord = tile * ivec2(TILE_WIDTH, TILE_HEIGHT);
    ivec2 end_coord = min(base_coord + ivec2(TILE_WIDTH, TILE_HEIGHT), ivec2(fb_info.resolution));

    int local_index_y = int(local_index / (PER_WAVE_TILES_X * PER_WAVE_TILES_Y));
    int mask_index = 32 * int(gl_WorkGroupID.x) + int(BITS_PER_SLICE) * local_index_y;

    uint group_binned = 0u;
    int mask_end = min(mask_index + int(BITS_PER_SLICE), fb_info.primitive_count_32);

    uint group_binned_mask = 1u << (BITS_PER_SLICE * local_index_y);

    // Wave uniform loop.
    while (mask_index < mask_end)
    {
        int linear_tile_lowres = (tile.y >> TILE_DOWNSAMPLE_LOG2) * MAX_TILES_X_LOW_RES + (tile.x >> TILE_DOWNSAMPLE_LOG2);
#if SUBGROUP
        // Mark as a wave uniform expression.
        int binned_bitmask_offset = subgroupBroadcastFirst(linear_tile_lowres * TILE_BINNING_STRIDE + mask_index);
#else
        int binned_bitmask_offset = linear_tile_lowres * TILE_BINNING_STRIDE + mask_index;
#endif
        uint low_res_binned = binned_bitmask_low_res[binned_bitmask_offset];
        uint binned = 0u;

        // Wave uniform loop.
        while (low_res_binned != 0u)
        {
            int i = findLSB(low_res_binned);
            low_res_binned &= ~uint(1 << i);

            int primitive_index = i + mask_index * 32;
            if (bin_primitive(uint(primitive_index), base_coord, end_coord))
                binned |= 1u << uint(i);
        }

        binned_bitmask[linear_tile * TILE_BINNING_STRIDE + mask_index] = binned;
        if (binned != 0u)
            group_binned |= group_binned_mask;
        group_binned_mask <<= 1u;

#if !UBERSHADER
        // Allocate instance offsets per mask.
        uint bit_count = uint(bitCount(binned));

#if SUBGROUP
        uint total_bit_count = subgroupAdd(bit_count);
        uint instance_offset = 0u;
        if (subgroupElect())
        {
            if (total_bit_count != 0u)
                instance_offset = atomicAdd(item_counts_per_variant[0].w, total_bit_count);
        }
        instance_offset = subgroupBroadcastFirst(instance_offset);
        instance_offset += subgroupInclusiveAdd(bit_count) - bit_count;
        tile_instance_offset[linear_tile * TILE_BINNING_STRIDE + mask_index] = uint16_t(instance_offset);

        // As a subgroup, we figure out how many work instances we need to create per primitive.
        uint overall_binned = subgroupOr(binned);
        // Wave uniform loop.
        while (overall_binned != 0u)
        {
            int i = findLSB(overall_binned);
            overall_binned &= ~uint(1 << i);
            int primitive_index = i + mask_index * 32;

            bool is_binned = (binned & (1u << uint(i))) != 0u;
            uvec4 primitive_ballot = subgroupBallot(is_binned);
            uint allocate_count = subgroupBallotBitCount(primitive_ballot);
            uint bit_offset = subgroupBallotExclusiveBitCount(primitive_ballot);

            uint variant_index = uint(state_indices[primitive_index]);
            uint work_offsets = 0u;
            if (subgroupElect())
            {
                if (allocate_count != 0u)
                    work_offsets = atomicAdd(item_counts_per_variant[variant_index].x, allocate_count);
            }

            work_offsets = subgroupBroadcastFirst(work_offsets) + bit_offset;
            if (is_binned)
            {
                tile_raster_work[work_offsets + uint(TILE_INSTANCE_STRIDE) * variant_index] =
                    u16vec4(uvec4(tile.x, tile.y, instance_offset, primitive_index));
                instance_offset++;
            }
        }
#else
        uint instance_offset = 0u;
        if (bit_count != 0u)
            instance_offset = atomicAdd(item_counts_per_variant[0].w, bit_count);
        tile_instance_offset[linear_tile * TILE_BINNING_STRIDE + mask_index] = uint16_t(instance_offset);

        while (binned != 0u)
        {
            int i = findLSB(binned);
            binned &= ~uint(1 << i);
            int primitive_index = i + mask_index * 32;
            uint variant_index = uint(state_indices[primitive_index]);
            uint work_offset = atomicAdd(item_counts_per_variant[variant_index].x, 1u);
            tile_raster_work[work_offset + uint(TILE_INSTANCE_STRIDE) * variant_index] =
                u16vec4(uvec4(tile.x, tile.y, instance_offset, primitive_index));
            instance_offset++;
        }
#endif

#endif

        mask_index++;
    }

    // Need to merge group mask here across the 16 slices, each slice worked on 2 bits.
    shared_group_binning[local_index_y][local_tile_y][local_tile_x] = group_binned;
    barrier();

    uint step = NUM_SLICES >> 1u;
    for (uint step = NUM_SLICES >> 1u; step >= 2u; step >>= 1u)
    {
        if (local_index_y < step)
            shared_group_binning[local_index_y][local_tile_y][local_tile_x] |= shared_group_binning[local_index_y + step][local_tile_y][local_tile_x];
        barrier();
    }

    if (local_index_y == 0u)
    {
        uint binned_bitmask_offset = uint(TILE_BINNING_STRIDE_COARSE * linear_tile);
        uint group_binned = shared_group_binning[0][local_tile_y][local_tile_x] | shared_group_binning[1][local_tile_y][local_tile_x];
        binned_bitmask_coarse[binned_bitmask_offset + gl_WorkGroupID.x] = group_binned;
    }
}
